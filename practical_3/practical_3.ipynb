{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Learning - Practical 3\n",
    "___________________________________________________\n",
    "\n",
    "In this notebook, we'll be going through the basics of applying a few-shot learning model to a text dataset. We'll make use of the NShot package to load a default text encoder, BERT, and apply it to a dataset of Amazon product reviews. We'll see how training would work. Because of limited compute resources, we won't be able to fully train our model on a large dataset, so we'll load an existing model and see how it performs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nshot as ns\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_device = 'cpu'\n",
    "model_device   = 'cpu'\n",
    "\n",
    "# Specify paths\n",
    "data_dir = '/home/shared/amazon_reviews/tutorial/'\n",
    "train_path = data_dir + 'train/'\n",
    "val_path   = data_dir + 'val/'\n",
    "test_path  = data_dir + 'test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. The Dataset\n",
    "___\n",
    "\n",
    "\n",
    "For this training example, we will use the Amazon product review dataset, you can find more information about this dataset here: https://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "In this dataset product reviews are given for a number of different product categories, from which we extract the raw text. The task is to determine the product category that each review is written about. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are planning on training we load both the training data, validation, and test data\n",
    "\n",
    "train_data      = ns.TextData(train_path, max_classes=50, max_per_class=100, min_per_class=10)\n",
    "validation_data = ns.TextData(val_path, max_classes=20, max_per_class=100, min_per_class=10)\n",
    "test_data       = ns.TextData(test_path, max_classes=20, max_per_class=100, min_per_class=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the training loop lets take a look at some of the numbers related to the datasets we just loaded. First we print the number of datapoints and the number of unique classes in each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = pd.DataFrame(data={\n",
    "    'Training':[\n",
    "        len(train_data), \n",
    "        len(set(train_data.labels))\n",
    "    ],\n",
    "    'Validation':[\n",
    "        len(validation_data),\n",
    "        len(set(validation_data.labels))\n",
    "    ],\n",
    "    'Test':[\n",
    "        len(test_data),\n",
    "        len(set(test_data.labels))\n",
    "    ]\n",
    "}).rename(index={0:'Datapoints',1:'Classes'})\n",
    "\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class structure\n",
    "\n",
    "Product categories on Amazon are hierarchical. A higher-level category, e.g. \"Arts, Crafts & Sewing\" may have subcategories, e.g. \"Craft Supplies\". All of the few-shot categories are based on the lowest tier of the hierarchy. We keep track of the structure of the hierarchy by adding '+' between tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = sorted(set(train_data.labels))\n",
    "val_labels = sorted(set(validation_data.labels))\n",
    "test_labels = sorted(set(test_data.labels))\n",
    "\n",
    "class_info = pd.DataFrame(data={'Training': train_labels,\n",
    "                               'Validation': val_labels + ['' for _ in range(len(train_labels)-len(val_labels))],\n",
    "                               'Test': test_labels + ['' for _ in range(len(train_labels)-len(test_labels))]\n",
    "                               })\n",
    "\n",
    "class_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that since we are working in the fewshot paradigm the classes in the training set and the classes in the validation set are entirely disjoint. \n",
    "\n",
    "Last thing to look at in the dataset is the distribution of the number of datapoints in each class. This can be a critical set of numbers to investigate and failure to properly handly imbalanced data can result in poor model performance when given real world data. For this dataset, every class has exactly 101 datapoints. We can easily check this as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives an object counting each unique value in the given list \n",
    "counter = Counter(train_data.labels)\n",
    "\n",
    "# counter.most_common() sorts our labels by which are the most frequent. \n",
    "for label, cnt in counter.most_common():\n",
    "    print(str(cnt) + ' \\t ' + label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual data points\n",
    "\n",
    "NShot's dataset objects arbitrarily order datapoints into a list, so we can look at individual data points by choosing an index. This returns two objects, the first is the raw text and the second is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "datapoint = train_data[idx]\n",
    "text, label = datapoint\n",
    "\n",
    "print(label.upper() + \": \" + text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. The Model\n",
    "\n",
    "For this notebook, we'll be leveraging BERT as an encoder. NShot provides us with a wrapper around a basic BERT model. By default, this uses the 'bert-base-uncased' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ns.BertEncoder(sequence_length=64, device=encoder_device)\n",
    "model   = ns.RCNet(encoder, fc_dim=64, n_blocks=2, device=model_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Training Run\n",
    "\n",
    "Note: Training text models requires a heavy preprocessing step. This can take 1-30 minutes depending on the cpu power available to the notebook.\n",
    "\n",
    "In practice, CPU is not going be enough to train this model very well. We may expect to hit ~48% accuracy on 5-shot, 5-way episodes but only if we train long enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = ns.train_model(\n",
    "    model, \n",
    "    train_data, \n",
    "    validation_data,\n",
    "    freeze_encoder_weights=True, \n",
    "    max_iterations=1,\n",
    "    train_with_negatives=False,\n",
    "    distractors=False,\n",
    "    query_size=8,\n",
    "    logging_period=25, \n",
    "    episodes_per_iteration=25,\n",
    "    log_dir='logs/text_logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the Results\n",
    "As training progresses you will see several directories and files created. It should have a structure something like this: \n",
    "\n",
    "```\n",
    "logs/text_logs/\n",
    "  |  logs.json\n",
    "  |  parameters.json\n",
    "  |  plots.png\n",
    "  \\--weights\n",
    "       |  best_weights.pt\n",
    "       |  iteration_#_weights.pt\n",
    "       |         :\n",
    "       |         :\n",
    "       \\  iteration_#_weights.pt\n",
    "```\n",
    "\n",
    "The file 'parameters.json' contains some of the important training parameters. Near the end of the file, it also lists 'Validation accuracy' which is the highest validation performance reached in training. This updates at the end of every logging period and is one way to get an idea of what is going on during training.\n",
    "\n",
    "Once the training run is complete we can use standard json tools to do deeper analysis of the machine readable logs.json file, which contains information from throughout the training run.\n",
    "\n",
    "Note: This is the most basic format for handling logging and in practice you might rely on more sophisticated experiment management tools such as MLFlow or Weights & Biases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/text_logs/parameters.json') as f:\n",
    "    log_data = json.load(f)\n",
    "    \n",
    "log_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots.png file saves loss and accuracy curves during training. The blue line represents performance on the training data, while the orange line represents validation data.\n",
    "\n",
    "A challenge for few-shot models is that they often require low learning rates, so we may not see a lot of movement for our short training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at the training curve\n",
    "training_curve_img = matplotlib.image.imread('logs/text_logs/plots.png')\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(16,12))\n",
    "matplotlib.pyplot.imshow(training_curve_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Loading an existing model\n",
    "___\n",
    "\n",
    "Our current model is constrained in two ways. First, it hasn't been given enough time to train. But if you did let this model train for quite some time, the performance on validation data would still be quite poor. This is because the second issue is the small number of training classes. In this tutorial dataset, we only have 50 training classes. Let's load a model that was both trained sufficiently long and was trained on 800 classes. We'll see the performance is quite improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ns.BertEncoder(sequence_length=128, device=encoder_device)\n",
    "model   = ns.RCNet(encoder, fc_dim=128, n_blocks=4, device=model_device)\n",
    "\n",
    "state_dict_file = '/home/shared/practical_3_logs/weights/best_weights.pt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the single command `load_weights` to get our previously learned weights loaded into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(state_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the warning that is thrown when loading weights. PyTorch has two basic modes a model can be in `train` and `eval`. If a model is in evaluation mode then it will not update gradient information as data is pushed through the model. Since we are about to evaluate the model on the test set this is just fine. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Evaluating the Model\n",
    "The evaluation function takes many of the same arguments as the training function. We still need to know how many classes per episode, how many examples per class and how many episodes in the iteration. The big difference is that we will only do one iteration and no gradients will be updated in the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = ns.run.evaluate(\n",
    "    model, \n",
    "    test_data, \n",
    "    positives_per_class=5,\n",
    "    number_of_episodes=5,\n",
    "    distractors=False,\n",
    "    negatives_per_class=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final test accuracy: {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
